<!DOCTYPE html><html lang="en" data-astro-cid-37fxchfa> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v5.1.1"><title>~ / trail / twelve-factor-agents - salnad</title><link rel="stylesheet" href="/_astro/index.CL29t4r1.css">
<style>header[data-astro-cid-56kjmc4t]{scrollbar-width:thin;scrollbar-color:#4b5563 #1f2937}.segment-container[data-astro-cid-56kjmc4t]{max-width:100%;min-width:0}.segment-link[data-astro-cid-56kjmc4t]{max-width:100%;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;display:inline-block}@media (min-width: 640px){.segment-link[data-astro-cid-56kjmc4t]{max-width:300px}}@media (min-width: 768px){.segment-link[data-astro-cid-56kjmc4t]{max-width:400px}}@media (min-width: 1024px){.segment-link[data-astro-cid-56kjmc4t]{max-width:500px}}
.trail-post[data-astro-cid-wvs66yus] p:first-of-type{display:inline}
[data-astro-image]{width:100%;height:auto;-o-object-fit:var(--fit);object-fit:var(--fit);-o-object-position:var(--pos);object-position:var(--pos);aspect-ratio:var(--w) / var(--h)}[data-astro-image=responsive]{max-width:calc(var(--w) * 1px);max-height:calc(var(--h) * 1px)}[data-astro-image=fixed]{width:calc(var(--w) * 1px);height:calc(var(--h) * 1px)}
</style></head> <body class="bg-black min-h-screen flex flex-col items-center justify-center font-['Comic_Sans_Mono',_monospace] px-[10%] py-[5%]" data-astro-cid-37fxchfa> <main class="text-center w-full md:w-1/2 mx-auto" data-astro-cid-37fxchfa>  <div class="max-w-3xl mx-auto px-4 py-12" data-astro-cid-wvs66yus> <header class="py-4 mb-8 overflow-x-auto" data-astro-cid-56kjmc4t> <nav class="flex flex-wrap items-center text-2xl justify-center" data-astro-cid-56kjmc4t> <div class="flex items-center segment-container" data-astro-cid-56kjmc4t>  <a href="/" class="px-2 py-1 transition-colors segment-link text-gray-500 hover:text-white hover:underline hover:decoration-dotted" title="✨ salnad" data-astro-cid-56kjmc4t> ✨ salnad </a> </div><div class="flex items-center segment-container" data-astro-cid-56kjmc4t> <span class="mx-2 text-gray-500 flex-shrink-0" data-astro-cid-56kjmc4t>/</span> <a href="/trail" class="px-2 py-1 transition-colors segment-link text-gray-500 hover:text-white hover:underline hover:decoration-dotted" title="🔎 trail" data-astro-cid-56kjmc4t> 🔎 trail </a> </div><div class="flex items-center segment-container" data-astro-cid-56kjmc4t> <span class="mx-2 text-gray-500 flex-shrink-0" data-astro-cid-56kjmc4t>/</span> <a href="/trail/2025-04-18/twelve-factor-agents" class="px-2 py-1 transition-colors segment-link text-white font-bold" title="twelve factor agents" data-astro-cid-56kjmc4t> twelve factor agents </a> </div> </nav> </header>  <div class="border-b border-gray-700 pb-8 mb-8" data-astro-cid-wvs66yus> <div class="text-gray-300" data-astro-cid-wvs66yus> <div class="prose prose-invert max-w-none" data-astro-cid-wvs66yus> <div class="trail-post text-left" data-astro-cid-wvs66yus> <a href="https://github.com/humanlayer/12-factor-agents" target="_blank" class="text-white hover:text-gray-300 transition-colors underline font-bold inline-block" data-astro-cid-wvs66yus> twelve factor agents </a> <span class="text-white text-sm" data-astro-cid-wvs66yus> —— </span> <p>this is an interesting piece by Dex Horthy of HumanLoop (an ai startup working in the LLMOps space). it mimics herokus “12 factors apps” (<em>of which i was honestly unaware of, my inexperience is showing</em> 🙈). i’ve listed some takeaways below!</p>
<h3 id="a-mix-non-detirminism-into-a-detirministic-system">(a) mix non-detirminism into a detirministic system</h3>
<blockquote>
<p><strong>I’ve been surprised to find</strong> that most of the products out there billing themselves as “AI Agents” are not all that agentic. A lot of them are mostly deterministic code, with LLM steps sprinkled in at just the right points to make the experience truly magical.</p>
</blockquote>
<p>reasons for this include —</p>
<p><strong>approaching building agentic capabilities as a “refactor” makes things more tenable</strong></p>
<blockquote>
<p>a small, focused approach ensures you can get results TODAY, while preparing you to slowly expand agent scope as LLM context windows become more reliable. (If you’ve refactored large deterministic code bases before, you may be nodding your head right now.)</p>
</blockquote>
<p><strong>you get the benefits of modularization</strong></p>
<blockquote>
<ol>
<li><strong>Manageable Context</strong>: Smaller context windows mean better LLM performance</li>
<li><strong>Clear Responsibilities</strong>: Each agent has a well-defined scope and purpose</li>
<li><strong>Better Reliability</strong>: Less chance of getting lost in complex workflows</li>
<li><strong>Easier Testing</strong>: Simpler to test and validate specific functionality</li>
<li><strong>Improved Debugging</strong>: Easier to identify and fix issues when they occur</li>
</ol>
</blockquote>
<p>this makes sense to me — throwing away a bunch of application code (in the short term) seems rather silly. and thinking of making your application more “agentic” as a slow refactor of increasingly LLM dependent code as capabilities increase seems way more likely to succeed than the “build out a new agent product” route</p>
<h3 id="b-llms-are-stateless-functions">(b) llms are stateless functions</h3>
<p>or as dex puts it —</p>
<blockquote>
<p>Make your agent a stateless reducer</p>
</blockquote>
<p>one of the existing biases that this post made realize is that i inherintly think of llms as “chats” — a continous thread of inputs from the user and messages from the LLM. but most LLM APIs are not inherintly stateful, that’s usually an abstraction added by the “agent library” applications are built on top of.</p>
<p>some neat examples of this from the post —</p>
<p><strong>compacting errors in the context window</strong></p>
<blockquote>
<p>you don’t need to just put the raw error back on, you can completely restructure how it’s represented, remove previous events from the context window, or whatever deterministic thing you find works to get an agent back on track.</p>
</blockquote>
<p><strong>using non-chat style context windows</strong></p>
<blockquote>
<p>(you can) Enable agents to be triggered by non-humans, e.g. events, crons, outages, whatever else. They may work for 5, 20, 90 minutes, but when they get to a critical point, they can contact a human for help, feedback, or approval.</p>
</blockquote>
<p><strong>pre-fetching context before the LLM call</strong></p>
<blockquote>
<p>If there’s a high chance that your model will call tool X, don’t waste token round trips telling the model to fetch it</p>
<p>You might as well just fetch [the data] and include them in the context window</p>
</blockquote>
<h3 id="c-own-as-much-as-you-can">(c) <strong>own as much as you can</strong></h3>
<p>a lot of the rules (<a href="https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-2-own-your-prompts.md">2: Own your prompts</a>, <a href="https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-3-own-your-context-window.md">3: Own your context window</a>, <a href="https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-8-own-your-control-flow.md">8: Own your control flow</a>) boiled down to <em>don’t give up too much to frameworks / apis</em>. it argues a lot of the simplicity of existing “agent frameworks” tend to obfuscate key parts of the process that are necessary to ensure your system is reliable (especially when models, best practices, and capabilities are changing as rapidly as they are).</p>
<h3 id="d-tool-calls-can-be-used-creatively">(d) tool calls can be used creatively</h3>
<p>for example, as <a href="https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-7-contact-humans-with-tools.md">factor 7 states</a> you can Contact humans with tool calls. the same tool call can also be handled differently depending on the state of the application or context, abstracting away some of the complexity as described in <a href="https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-4-tools-are-structured-outputs.md">factor 4</a>.</p>
<h3 id="e-everything-is-context-engineering">(e) everything is context engineering</h3>
<blockquote>
<p>Remember: The context window is your primary interface with the LLM. Taking control of how you structure and present information can dramatically improve your agent’s performance.</p>
<ul>
<li>Context includes: prompts, instructions, RAG documents, history, tool calls, memory</li>
<li>
<ul>
<li>Optimize context format for token efficiency and LLM understanding</li>
</ul>
</li>
<li>Consider custom context formats beyond standard message-based approaches</li>
<li>Structure information for maximum density and clarity</li>
<li>Include error information in formats that help LLMs recover</li>
<li>Control what information gets passed to LLMs (filter sensitive data)</li>
</ul>
</blockquote>
<p>a great read, and something that is pushing me further from SDKs in my own experiments and more towards trying to homebrew something. i might try using the <a href="https://docs.boundaryml.com/home">BAML</a> language linked throughout this post</p>
<p>and now a haiku!</p>
<blockquote class="haiku">
if it doesn’t have <br>
llms all the way down <br>
is it an agent?
</blockquote> </div> </div> </div> <div class="mt-4 flex items-center flex-wrap text-left" data-astro-cid-wvs66yus> <div class="mr-4" data-astro-cid-wvs66yus> <div class="flex flex-wrap gap-x-6 text-sm text-gray-400"> <div>  2025-04-18 </div> <div>  2025-04-18 </div> </div> </div> <div class="text-sm text-gray-500 inline-flex flex-wrap"><span><a href="/tag/llms" class="hover:text-gray-300 transition-colors">
#llms</a>, </span><span><a href="/tag/agents" class="hover:text-gray-300 transition-colors">
#agents</a>, </span><span><a href="/tag/software-engineering" class="hover:text-gray-300 transition-colors">
#software-engineering</a>, </span><span><a href="/tag/dex-horthy" class="hover:text-gray-300 transition-colors">
#dex-horthy</a></span></div> </div> </div> </div>  </main>  </body></html> 